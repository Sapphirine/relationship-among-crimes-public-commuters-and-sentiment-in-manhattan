{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read HTML module\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "# Set the jupyter to display all the columns adn rows\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset from MTA webset\n",
    "\n",
    "def download_data(url,start,stop,log_name):\n",
    "    \"\"\"\n",
    "    This function download selected datasets(prior 10/18/14) from MTA website, by finding the selected datasets by HTML elements.\n",
    "    Then consolidate all the downloaded datasets to one large dataframe.\n",
    "    Also, log the downloaded files information, such as file date, file_link, number of rows, and number of columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    col_name_new = ['C/A','UNIT','SCP','STATION','LINENAME','DIVISION','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "    df = pd.DataFrame(columns = col_name_new)\n",
    "    \n",
    "\n",
    "    # Log of downloading\n",
    "    logFile  = open(log_name, 'w')  # 'Download_Log.txt'\n",
    "    logFile.write('file_date;file_link;number_of_rows;number_of_columns')\n",
    "    \n",
    "    # get HTML code\n",
    "    jpy = pq(url) \n",
    "\n",
    "    for i in range(start, stop, 2):\n",
    "        # retrieve file path\n",
    "        item = jpy('#contentbox > div > div > a:nth-child({})'.format(i))\n",
    "        fileDate = item.text()\n",
    "        filePath = 'http://web.mta.info/developers/' + item.attr('href')\n",
    "\n",
    "        # get data from txt, save to csv, and append to datafram\n",
    "        data = pd.read_csv(filePath, sep=\",\", header=0, names = col_name_new)\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        # data.to_csv('./raw_data/MTA_data_{}.csv'.format(re.sub(r',','',fileDate)))\n",
    "\n",
    "        # log the downloaded file information\n",
    "        record = str(fileDate) + ';' + str(filePath) + ';' + str(data.shape[0]) + ';' + str(data.shape[1])\n",
    "        logFile.write('\\n' + record)\n",
    "    \n",
    "    logFile.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_irregular_event(df):\n",
    "    \"\"\"\n",
    "    In the original data, there are factors that may impact the data. (ie. Hardware failure, \"IRREGULAR\" audit event)\n",
    "    Clean the data to filter out 'IRREGULAR' audit event.\n",
    "    \"\"\"\n",
    "    # Remove records where DESC (audit event) != REGULAR\n",
    "    df = df[df.DESC == 'REGULAR']\n",
    "\n",
    "    return df\n",
    "def add_hourly_entries(df):\n",
    "    \"\"\"\n",
    "    The 'ENTRIES' variable recorded in the MTA data are cumulative entries of the turnstile per row. \n",
    "    Considering the data for a single turnstile machine (unique SCP, C/A, and UNIT),\n",
    "    we want to add a new column symbolizing the incremental number of entries since the last recording time.\n",
    "    \n",
    "    This function is to add a new column, calculate the difference between ENTRIES in the current row and the\n",
    "    previous row, and assign the difference to the new column. When there is NaN, fill it with 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    HOURLY_ENTRIES = df.ENTRIES - df.ENTRIES.shift(1) \n",
    "    df['HOURLY_ENTRIES'] = HOURLY_ENTRIES.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_hourly_exits(df):\n",
    "    \"\"\"\n",
    "    The 'EXITS' variable recorded in the MTA data are cumulative exits of the turnstile per row. \n",
    "    Considering the data for a single turnstile machine (unique SCP, C/A, and UNIT),\n",
    "    we want to add a new column symbolizing the incremental number of exits since the last recording time.\n",
    "    \n",
    "    This function is to add a new column, calculate the difference between EXITS in the current row and the\n",
    "    previous row, and assign the difference to the new column. When there is NaN, fill it with 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    HOURLY_EXITS = df.EXITS - df.EXITS.shift(1) \n",
    "    df['HOURLY_EXITS'] = HOURLY_EXITS.fillna(0)\n",
    "    return df\n",
    "\n",
    "def add_busyness(df):\n",
    "    \"\"\"\n",
    "    Define busyness as sum of ebtries and exits. Add a new column and assign busyness to it.\n",
    "    \"\"\"\n",
    "    \n",
    "    BUSYNESS = df.HOURLY_ENTRIES + df.HOURLY_EXITS \n",
    "    df['BUSYNESS'] = BUSYNESS\n",
    "    return df\n",
    "\n",
    "\n",
    "def time_to_hour(time):\n",
    "    \"\"\"\n",
    "    Input 00:00:00 (hour:minute:second).\n",
    "    Extract and return the hour from input.\n",
    "    \"\"\"\n",
    "    # return pd.to_datetime(time).hour\n",
    "    return int(time.split(':')[0])\n",
    "\n",
    "def date_to_month(date):\n",
    "    \"\"\"\n",
    "    Input mm-dd-yy (month-day-year).\n",
    "    Extract and return the month from input date.\n",
    "    \"\"\"\n",
    "    # return pd.to_datetime(date).month\n",
    "    return int(date.split('/')[0])\n",
    "               \n",
    "def date_to_year(date):\n",
    "    \"\"\"\n",
    "    Input sting mm-dd-yy (month-day-year).\n",
    "    Extract and return the year from input date.\n",
    "    \"\"\"\n",
    "    # return pd.to_datetime(date)\n",
    "    return int(date.split('/')[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTA_data(url,start,stop,log_name,date_tag):\n",
    "    \n",
    "    # download data\n",
    "    df = download_data(url,start,stop,log_name)\n",
    "    df.to_csv('MTA_data_{}.csv'.format(date_tag))\n",
    "    \n",
    "    # filter illegitimate data\n",
    "    df = remove_irregular_event(df)\n",
    "    df.to_csv('MTA_data_regular_{}.csv'.format(date_tag))\n",
    "    \n",
    "    # add hourly incremental entries\n",
    "    df = df.groupby(['C/A','UNIT','SCP']).apply(\n",
    "        add_hourly_entries)\n",
    "    \n",
    "    # add hourly incremental exits\n",
    "    df = df.groupby(['C/A','UNIT','SCP']).apply(\n",
    "        add_hourly_exits)\n",
    "\n",
    "    # add a 'HOUR', 'MONTH' and 'YEAR' column \n",
    "    df['HOUR'] = df['TIME'].map(time_to_hour)\n",
    "    df['MONTH'] = df['DATE'].map(date_to_month)\n",
    "    df['YEAR'] = df['DATE'].map(date_to_year)\n",
    "    \n",
    "    df.to_csv('MTA_data_hour_{}.csv'.format(date_tag))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"http://web.mta.info/developers/turnstile.html\"\n",
    "jpy = pq(url)\n",
    "for i in range(2*len(jpy('#contentbox > div > div > a'))):\n",
    "    if (jpy('#contentbox > div > div > a:nth-child({})'.format(i)).text() == \"Saturday, October 18, 2014\"):\n",
    "        stop = i+1\n",
    "        print(\"end_point = \" + str(i))\n",
    "    if (jpy('#contentbox > div > div > a:nth-child({})'.format(i)).text() == \"Saturday, December 27, 2014\"):\n",
    "        start = i\n",
    "        print(\"start_point = \" + str(i))\n",
    "        \n",
    "log_name = 'Download_Log_new.txt'\n",
    "date_tag = 'y2014_new' # change here accordingly\n",
    "df = MTA_data(url,start,stop,log_name,date_tag)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./MTA_data_hour_y2014_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    HOURLY_ENTRIES and HOURLY_EXITS contains negative value and abnormally large value (ie. the max is 931476882).\n",
    "    Assuming it takes 1 second for 1 people enter the turnstile, \n",
    "    there can be at max 14,400 people entering turnstile in 4 hours. \n",
    "    So in theory, considering a buffer, any HOURLY_ENTRIES (or HOURLY_EXITS) greater than 20000 is not possible. \n",
    "    Also HOURLY_ENTRIES and HOURLY_EXITS obviously cannot be negative.\n",
    "    \n",
    "    This function replace the negative and greater than 20000 HOURLY_ENTRIES by the mean of the group(ie.SCP,MONTH) that they are in.\n",
    "    Then calculate the \"BUSYNESS\".\n",
    "    \"\"\"\n",
    "\n",
    "    # clean 'HOURLY_ENTRIES'\n",
    "    df['HOURLY_ENTRIES'] = df.groupby(['SCP','MONTH']).HOURLY_ENTRIES.transform(\n",
    "        lambda x: np.where((x<0)|(x>20000),x.mask((x<0)|(x>20000)).mean(),x))\n",
    "    \n",
    "    # clean 'HOURLY_EXITS'\n",
    "    df['HOURLY_EXITS'] = df.groupby(['SCP','MONTH']).HOURLY_EXITS.transform(\n",
    "        lambda x: np.where((x<0)|(x>20000),x.mask((x<0)|(x>20000)).mean(),x))\n",
    "    \n",
    "    # add busyness\n",
    "    df['BUSYNESS'] = df.HOURLY_ENTRIES + df.HOURLY_EXITS \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_modified(hour):\n",
    "    if hour > 20 or hour <= 0 : return 0\n",
    "    if 0 < hour <= 4 : return 4\n",
    "    if 4 < hour <= 8 : return 8\n",
    "    if 8 < hour <= 12 : return 12\n",
    "    if 12 < hour <= 16 : return 16\n",
    "    if 16 < hour <= 20 : return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_final = pd.read_csv(\"./mapping_final.csv\", sep=\",\")\n",
    "df_master = pd.merge(df_final, mapping_final, how='left', on=['C/A','UNIT'], sort=True, copy=True, indicator=True)\n",
    "df_master['Date_ID'] = (df_master['DATE']).astype('category').cat.codes \n",
    "df_master = df_master.rename(columns = {'Station ID':'Station_ID'})\n",
    "df_master['HOUR_modified'] = df_master['HOUR'].map(hour_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.to_csv(path_or_buf='./df_master_new.csv',sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HOUR_LIST = [0,4,8,12,16,20]\n",
    "col_name = ['Station_ID','HOURLY_ENTRIES','HOURLY_EXITS','Date','HOUR_modified','Station_name','Latitude','Longitude']\n",
    "df_new = pd.DataFrame(columns = col_name)\n",
    "for i in range(len(df_master['Date_ID'].unique())):\n",
    "    \n",
    "    for j in HOUR_LIST:\n",
    "        temp = pd.DataFrame()\n",
    "        temp = df_master[(df_master.Date_ID == i)&(df_master.HOUR_modified == j)].groupby('Station_ID')['HOURLY_ENTRIES','HOURLY_EXITS'].sum().round(2)\n",
    "        temp = temp.reset_index()\n",
    "        if len(temp)==0:\n",
    "            continue\n",
    "        else: \n",
    "            temp['Date'] = np.full((len(temp),1),df_master.loc[df_master.Date_ID == i,['DATE']].drop_duplicates().values)\n",
    "            temp['HOUR_modified'] = np.full((len(temp),1),df_master.loc[df_master.HOUR_modified == j,['HOUR_modified']].drop_duplicates().values)\n",
    "            temp = pd.merge(temp, df_master.loc[:,['Station_ID','Station_modified','GTFS Latitude','GTFS Longitude']].drop_duplicates(), how='left', on=['Station_ID']).rename(\n",
    "            columns = {'Station_modified':'Station_name','GTFS Latitude':'Latitude','GTFS Longitude':'Longitude'})\n",
    "            df_new = df_new.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(path_or_buf='./final_table_after.csv',sep=',',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
